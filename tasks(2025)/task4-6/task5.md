# Task 5 深度学习与深度学习现代框架

## 学习目的

在 Task 4 中，你已经通过亲手实现反向传播，锻炼了作为人工智能工程师的核心技能。现在，你将在此基础上，进一步深入学习和实践专业方向的核心技术。本轮考核将是你专业方向的重要阶段，你将深入学习那些定义了现代深度学习的模块化设计思想与核心网络架构。

这次，你的任务不再是构建一个写死的两层网络，而是要学会如何设计和实现一个可扩展、可组合的深度神经网络，并最终亲手实现计算机视觉领域的核心技术——卷积神经网络（Convolutional Neural Network, CNN）。

## 学习内容

本轮的学习将从整体架构转向模块化实现，你将深入理解并实现构成现代神经网络的各个独立组件：

* 网络优化与正则化：批量归一化（Batch Normalization）、Dropout
* 模块化网络设计：将网络层（如全连接层、ReLU 激活层）抽象为独立的、拥有 `forward` 和 `backward` 接口的模块
* 卷积神经网络核心：卷积层（Convolutional Layer）的前向与反向传播、池化层（Pooling Layer）的前向与反向传播
* 现代框架实践：在手动实现所有核心组件后，使用高层框架（如 PyTorch）快速搭建一个高性能的 CNN 模型

## 学习要求

本轮考核的难度相较于 Task 4 有显著提升，主要体现在以下两个方面：

1. 抽象思维的转变：你需要从为整个网络编写一个统一的 `loss` 和 `gradient` 函数，转变为为每一个独立的层编写 `forward` 和 `backward` 函数。这种模块化的设计思想是所有现代深度学习框架的基石。
2. 数学与实现的挑战：卷积层的反向传播在数学上和实现上都比全连接层更为复杂。你需要花费大量时间阅读课程笔记，理解梯度是如何在卷积和池化操作中流动的。

请务必将课程笔记（Notes）作为你最主要的学习材料。只有在真正理解了每一层的计算原理后，你才有可能成功地完成代码实现。

## 作业

关于本次的任务，你需要完成以下内容——

* 作业内容中提到的所有文档（不出意外的话是 2 份）
* 完成作业一
* 从作业二、三中选择一项完成
* 作业四选做

### 作业 1：完成 CS231n Assignment 2

核心任务：完成 [CS231n Assignment 2](https://cs231n.github.io/assignments2025/assignment2/)

本次作业分为三个循序渐进的部分，将引导你完成一次从底层构建到高层应用的完整体验：

#### 模块化全连接网络

在这一部分，你将改进 Task 4 中的整体化网络设计，开始构建一个可以自由堆叠层数的深度神经网络。你需要：

* 为每一个基础层（Affine、ReLU、Softmax Loss 等）实现独立的 `forward` 和 `backward` 函数。
* 在此基础上，实现批量归一化（Batch Normalization）和 Dropout 层的前向与反向传播。
* 将这些独立的层组合起来，构建一个可以任意指定层数和隐藏单元数量的全连接网络。
* 实现一个通用的 `Solver` 类来训练你的模型，并用它来寻找最佳的网络配置。

#### 卷积神经网络

这是本次作业的核心。你将深入学习 CNN 的内部机制，实现其最重要的两个组成部分：

* 卷积层（Convolutional Layer）：实现其 `forward` 和 `backward` 传播。这是整个作业中最具挑战性的部分。
* 最大池化层（Max-Pooling Layer）：实现其 `forward` 和 `backward` 传播。
* 将这些新的卷积组件与你之前实现的全连接层组合起来，构建一个真正的卷积神经网络。

#### 现代框架

在经历了手动实现所有核心组件的过程之后，你将体验到现代深度学习框架的强大与便捷。在这一部分，你需要：

* 使用 PyTorch 重新搭建一个更为复杂的卷积神经网络。
* 利用框架提供的自动求导、GPU 加速等功能，在 CIFAR-10 数据集上训练你的模型，并冲击尽可能高的准确率。

> 完成这次作业后，你将深刻理解一个重要问题：「我们为什么需要 PyTorch 这样的框架？」因为你已经亲身经历了完整的底层实现过程。这种从底层到高层的学习路径，将让你对深度学习的理解远超仅使用现成库的学习者。

#### 作业 1 - 作业要求

在完成作业后，你需要写一份**文档**，内容包括但不限于：

1. 各个模块的实现细节与数学原理
2. 各个模型在 CIFAR-10 数据集上的性能比较与分析
3. 你在实现过程中遇到的挑战与解决方案
4. 为什么会出现 PyTorch 这样的框架？它解决了哪些你在手动实现中遇到的问题？

### 作业 2：自定义数据集构建与数据增强

CS231n 和很多教程都是直接用 torchvision.datasets.CIFAR10，数据也是打包好的。

但现实世界的 AI 工程师，90% 的时间在处理乱七八糟的数据。

本轮作业要求你自己构建一个图像分类数据集，并实现数据增强管道。

#### 拟定题目

请确定一个你感兴趣的多分类主题（至少 3 个类别）。

例如：

1. 猫咪 vs 狗狗 vs 仓鼠
2. 剪刀 vs 石头 vs 布
3. 你最喜欢的三个动漫角色
4. 三种不同的食物
5. 自行拟题目

#### 收集数据

利用爬虫或者手动收集所需要的图片，每个类别至少 50 张图片，并将它们整理到合适的文件夹结构中，例如：

```tree
dataset/
    train/
        class1/
            img1.jpg
            img2.jpg
            ...
        class2/
            img1.jpg
            img2.jpg
            ...
        class3/
            img1.jpg
            img2.jpg
            ...
    val/
        class1/
            img1.jpg
            img2.jpg
            ...
        class2/
            img1.jpg
            img2.jpg
            ...
        class3/
            img1.jpg
            img2.jpg
            ...
```

要求：

1. 图片不需要裁剪整齐，尺寸可以不一致。
2. 严禁直接下载 Kaggle 或其他网站上已经打包好的 .zip 格式数据集。

#### 数据集类

你需要继承 torch.utils.data.Dataset 类，实现你自己的数据集加载器。

你的代码结构应该包含：

* `__init__`：初始化文件路径，读取图片列表。
* `__len__`：返回数据集的大小。
* `__getitem__`：根据索引读取图片，转换色彩空间（如 RGB），并应用数据预处理/增强。

你的数据集中可能包含损坏的图片（无法读取）或者非 RGB 格式（如 CMYK 或 灰度图）的图片，你的代码需要具备鲁棒性，能够处理或过滤掉这些异常情况，而不是直接报错崩溃。

#### 数据增强

请使用 torchvision.transforms 或 albumentations 库设计一套增强策略，包括但不限于：

* 几何变换：随机旋转、翻转、裁剪。
* 色彩变换：亮度、对比度、饱和度调整。
* 进阶（选做）：尝试使用 Cutout, Mixup 等高级增强技巧。

#### 验证与可视化

你需要编写脚本来验证你的数据集是否工作正常。

使用 DataLoader 加载一个 Batch 的数据。

利用 matplotlib 将这个 Batch 中的图片及其对应的标签（Label）可视化出来。

展示同一张图片在应用了不同的数据增强策略后的效果对比。

#### 作业 2 - 作业要求

在完成作业后，你需要写一份**文档**，内容包括但不限于：

1. 你构建了什么数据集？数据来源是哪里？包含多少个类别和样本？
2. 展示你的 CustomDataset 类的代码，并解释你是如何处理图片读取和异常值的。
3. 展示你的 transforms 配置。
    1. 贴出 DataLoader 读取出的 Batch 可视化截图。
    2. 对比原始图片与增强后的图片，分析增强策略是否合理
4. 在处理脏数据的过程中，你踩了哪些坑？（例如图片后缀是 .jpg 但实际是 png 格式？图片损坏导致训练中断？）

### 作业 3：数学建模 - 2025 电工杯 A 题（的问题 2 续）

在 Task 4 中，你已经初步接触了 2025 电工杯 A 题的问题 2，并使用默认参数跑通了几个基础模型。现在，你需要在此基础上，进行评估与改进。

本次作业要求你在 Task 4 的基础上，通过特征工程挖掘数据潜能，并通过超参数调优压榨模型能力，然后进行误差分析。

你需要做的工作包括数据特征工程，对 Task4 提到的 SVR，XGBoost 进行调参，误差分析以及引入 CNN 进行对比。

本次作依旧禁止使用深度学习模型（CNN 除外）。请专注于挖掘传统机器学习模型的潜力。

#### 特征工程

原始数据只有时间和功率，信息量远远不够。请尝试构造以下特征，并分析它们对模型的影响。

当然，你也可以尝试其他你认为有用的特征。

1. 时间特征：将时间戳拆解为小时、月份、季节等离散特征。
2. 滞后特征：构造过去时间点的功率值作为特征（例如：前15分钟、前1小时、昨天同一时刻的功率）。
3. 统计特征：计算滑动窗口内的统计值（例如：过去3小时的均值、最大值、标准差）。

思考以下问题：

1. 为什么这些特征可能有助于提升模型性能？如果没有提升，可能的原因是什么？如果提升了，具体提升了多少？为什么会提升？
2. 在日前预测场景下，思考哪些滞后特征是真实可用的？（例如：昨天的同一时刻 vs 刚刚过去的 15 分钟）
3. 在预测未来第 7 天的数据时，你无法直接获得昨天（即第 6 天）的真实功率作为特征输入。此时你的模型该如何运行？是使用预测值代替真实值（递归预测），还是专门训练一个预测第 7 天的模型？
4. 给出的特征不一定正确，请分析可能存在的问题，并提出改进方案。

#### 模型调参

请对 SVR 和 XGBoost 模型进行超参数调优。你可以使用网格搜索（Grid Search）、随机搜索（Random Search）、贝叶斯优化（Bayesian Optimization）等方法，寻找最佳的模型参数组合。

你需要记录下调优前后的参数变化，以及对应的验证集分数。

#### 误差分析

请使用赛题附录中的误差分析方法，对模型的预测结果进行深入分析。

你可以使用 RMSE、MAE 等指标，分析模型在不同时间段下的表现差异。

在此基础上你需要绘制以下可视化图表：

1. 时序对比图：画出测试集中某几天的 真实值 vs 预测值 曲线。
2. 残差分布图：画出 预测值 - 真实值 的分布直方图，观察误差是否符合正态分布。
3. 特定场景分析：单独截取清晨/黄昏（功率变化快）和正午（功率峰值）时段，观察模型在哪个时段表现最差。

#### 引入 CNN 进行对比

此前的模型均为传统机器学习模型。现在，请你尝试引入卷积神经网络（CNN）进行对比。

你可以将时间序列数据转换为适合 CNN 输入的格式，然后设计一个简单的 CNN 模型进行训练。

可以使用 1D-CNN，也可以使用 2D-CNN（将滑动窗口的数据视作图像，例如将 (Time_Window, Features) 的矩阵直接看作单通道图像）。主要推荐 1D-CNN，这更符合时序数据的直觉。

训练完毕后，比较 CNN 模型与传统模型的预测效果，然后思考以下问题：

1. CNN 的引入是否提升了模型的预测准确率？
2. 如果 CNN 没有提升准确率，可能的原因是什么？可能的改进方向有哪些？
3. 如果 CNN 提升了准确率，具体提升了多少？是在哪些时间段或条件下提升最明显？
4. CNN 相较于传统模型，在训练时间、计算资源消耗等方面有何不同？
5. CNN 对时间序数据的特征提取能力，是否优于传统模型？为什么？
6. CNN 的可解释性如何？相比传统模型，是否更难以理解其预测逻辑？

#### 作业 3 - 作业要求

在完成作业后，你需要写一份**文档**，内容包括但不限于：

1. 特征工程的方法与效果
2. 调参之后，你选择的最终模型参数配置
3. 误差分析的方法与结果
4. CNN 模型的设计与训练过程
5. 可视化你的结果

以及你遇到的问题，等等。

### 作业 4：根据 MNIST 数据集实现一个简单的识别数字的 Demo（选做）

人工智能的高级框架不只有 PyTorch，还有 TensorFlow，Keras 等等。

目前，Keras 已经被集成到 TensorFlow 中，成为其高级 API。

TensorFlow.js 是 TensorFlow 的 JavaScript 版本，可以直接在浏览器中运行深度学习模型。

本次作业要求你实现并部署一个基于 TensorFlow.js 的 MNIST 手写数字识别 Web 应用。

该项目的最终成果可以在[这里](https://shaddocknh3.github.io/tfjs-mnist-digit-recognizer/)体验。

本次作业的目标是让你亲历一个人工智能应用从训练到部署的全过程。你可以以[该项目](https://github.com/ShaddockNH3/tfjs-mnist-digit-recognizer)为基础框架，核心识别模型需要你亲手训练。

> 此后简称为该项目，不列出链接。

#### 训练识别模型

原项目（旧版本）中的模型存在版本兼容性以及无法兼容手机端的问题。

由于浏览器环境主要运行 TensorFlow.js，无法直接运行 PyTorch 和 TensorFlow。

你的任务是使用 Keras / PyTorch，在经典的 MNIST 数据集上，从零开始构建并训练一个卷积神经网络（CNN）。

你需要自行设计网络结构、选择优化器和损失函数，并进行超参数调整，以达到尽可能高的识别准确率。

训练完成后，你将得到一个 Keras / PyTorch 模型文件（通常是 `.h5` 格式或 `.pt` 格式）。

#### 模型转换

你需要通过转换工具，将训练好的模型迁移到 Web 环境中。

如果你采用了 Keras 进行训练，你需要使用 `tensorflowjs_converter` 将 Keras 模型直接转换为 TensorFlow.js 格式。

如果你采用了 PyTorch 进行训练，你需要把训练好的模型导出为 ONNX 格式，然后使用 onnx-tf 等工具将 ONNX 模型转换为 TensorFlow SavedModel，再转换为 TensorFlow.js 格式。

最终，你将得到两个文件：`model.json` 和一个 `.bin` 权重文件。

#### 前端实现

你可以 fork 该项目，然后替换原仓库 model 文件夹下的两个训练文件。

在你完成了文件替换后，你还需要修改 index.html 的第 6 行为自己的 GitHub 用户名。

当然你也可以从零开始实现一个前端页面，要求功能与该项目类似即可。

在你完成了整个项目后，你需要通过 GitHub Pages，将你的项目部署为一个公开可访问的网页。

在 PC 和移动端打开你的网页，在画板上写下数字，验证识别功能是否正常工作。

#### 参考资料

* [参考实现：使用 Keras.js 的旧版思路](https://github.com/starkwang/keras-js-demo)
* [参考教程：从训练到部署的详细步骤](https://www.cnblogs.com/chinasoft/p/17084356.html)
* [TensorFlow.js 官方文档](https://www.tensorflow.org/js/guide?hl=zh-cn)

## 作业要求

1. 不要抄袭
2. 遇到不会可以多使用搜索引擎，实在没有找到解决方法可以来群里提问，作为一个CSer学习提问的方式也非常重要，强烈建议阅读[Stop-Ask-Questions-The-Stupid-Ways](https://github.com/tangx/Stop-Ask-Questions-The-Stupid-Ways/blob/master/README.md)这篇文章
3. 不限制使用 ChatGPT 等大语言模型工具，但你需要确保你了解模型生成的内容的每一个细节，最好你可以在使用大语言模型生成的代码部分注释上「reference from ChatGPT」这样的内容
4. 你还需要学习基本的 Git 的使用，所有考核都采用 Git 的方式进行上传
5. 作业内容可能会进行更新，请保持关注

## 作业提交方式

1. 你需要学习 GitHub 的使用，创建一个你自己的仓库用来存放你的代码实现
2. 接着你需要学习如何使用 Git 进行 PR 操作，在 [solutions](https://github.com/west2-online-reserve/collection-ai) 中进行操作
